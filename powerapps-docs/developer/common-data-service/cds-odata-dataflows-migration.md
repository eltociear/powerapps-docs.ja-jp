---
title: データフロー OData コネクタを使用する Common Data Service 環境間でデータを移行する
author: denisem-msft
ms.reviewer: nabuthuk
description: データフロー OData コネクタを使用して Common Data Service の環境間でデータを移行する。
ms.date: 05/05/2020
ms.service: powerapps
ms.topic: article
ms.author: demora
search.app:
- PowerApps
ms.openlocfilehash: 056c1d70db7eed2ef7c6d31d0c9ff4de7f59f155
ms.sourcegitcommit: c90ed15cafdb804b602a1e4c12e6cf0e78fe645c
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 05/21/2020
ms.locfileid: "3389826"
---
# <a name="migrate-data-between-common-data-service-environments-using-the-dataflows-odata-connector"></a>データフロー OData コネクタを使用する Common Data Service 環境間でデータを移行する

Common Data Service[Web API](/powerapps/developer/common-data-service/webapi/overview) は OData および Oauth をサポートする任意のテクノロジで動作します。 Common Data Service でのデータの出し入れに使用できるオプションはたくさんあります。 OData コネクタはデータフローの 1 つであり、Common Data Service での大規模なデータセットの移行と同期をサポートするように設計されています。 

この記事では、データフロー OData コネクタを使用する Common Data Service 環境間のデータの移行方法について説明します。 

## <a name="prerequisites"></a>前提条件

- ソース環境とターゲット環境の両方に対するシステム管理者、またはシステム カスタマイザーのセキュリティ ロールのアクセス権限。

- Power Apps、Power Automate、Common Data Service ライセンス (アプリごと、またはユーザーごと)。

- 2 つの Common Data Service [データベースの環境](/power-platform/admin/create-environment#create-an-environment-with-a-database)。

## <a name="scenarios"></a>シナリオ

 - 1 回限りの環境間またはテナント間の移行が必要です (例: geo 間移行など)。

 - 開発者は、運用環境で使用されているアプリを更新する必要があります。 変更を簡単に作成するには、開発環境でテストデータが必要です。 

## <a name="step-1-plan-out-the-dataflow"></a>ステップ 1: データフローを計画する

1. ソース環境とターゲット環境を特定します。

    - **ソース環境**はデータの移行元です。 

    - **ターゲット環境**はデータの移行先です。 

1. エンティティがターゲット環境ですでに定義されていることを確認します。 理想としては、両方の環境が同じソリューションで定義された同じエンティティを持つことです。

1. 関連付けをインポートする場合、複数のデータフローが必要です。

    一 (親/独立) 対多 (子/依存) のエンティティには、個別のデータフローが必要です。 対応する子エンティティのフィールドに正しくマップするには、親のデータを最初にロードする必要があるため、親データフローを子エンティティの前に実行するように構成します。

## <a name="step-2-get-the-odata-endpoint"></a>ステップ 2: OData エンドポイントを取得する 

Common Data Service は OData エンドポイントを提供します。これには、データフロー コネクタを使用して認証する追加の構成を必要としません。 ソース環境へ接続は比較的簡単です。 

この記事では、OData コネクタを使用して新しいデータフローを設定する方法について説明します。 データフローが対応しているすべてのデータソースへの接続に関する情報については、[データフローの作成](https://docs.microsoft.com/powerapps/maker/common-data-service/create-and-use-dataflows)を参照してください。 


**ソース**環境から、環境の [OData エンドポイント](https://docs.microsoft.com/powerapps/developer/common-data-service/view-download-developer-resources) を取得します :

1. [Power Apps](https://make.powerapps.com) にサインインします。

1. 右上隅から必要なソース環境を選択します。

1. 右上の **設定** 歯車アイコンを選択し、続いて**詳細設定**を選択します。

1. **設定**ページで、**設定**の横にあるドロップダウン矢印を選択してから、**カスタマイズ**を選択します。

1. **カスタマイズ** ページで、**開発者リソース**を選択します。

1. **サービス ルート URL** をメモ帳にコピーします。

    > [!div class="mx-imgBorder"]
    > ![開発者リソースのサービス ルート URL をコピーする](./media/get-odata-endpoint-url.png "開発者リソースのサービス ルート URL をコピーする")
 
## <a name="step-3-create-a-new-odata-dataflow"></a>ステップ 3: 新しい OData データフローを作成する

**ターゲット**環境で、OData コネクタを使用して新しいデータフローを作成します。

1. [Power Apps](https://make.powerapps.com) にサインインします。

1. 右上隅から必要な環境を選択します。

1. 左のナビゲーション ウィンドウで、**データ**メニューを展開し、続いて**データフロー**を選択します。

1. **新規データフロー**を選択して、新しいデータフローを作成します。 データフローにわかりやすい名前を指定します。 **作成**を選びます。
   > [!div class="mx-imgBorder"]
   > ![新しいデータフローを要求する](./media/enter-name-for-new-dataflow.png "新しいデータフローを要求する")

1. **OData** コネクタを選択します。

    > [!div class="mx-imgBorder"]
    > ![OData ソースの選択](media/select-odata-data-source.png "OData ソースの選択")

1. **接続設定ダイアログ** ボックスで、フィールドの値を入力します。

    > [!div class="mx-imgBorder"]
    > ![フィールド値が正しいことを確認する](./media/enter-odata-connector-parameters.png "フィールド値が正しいことを確認する")


    | フィールド | 内容 |
    |--|--|
    | URL | 接続設定の URL フィールドにサービス ルート URL を入力します。 |
    | Connection | 新しい接続を作成します。 これは、以前にデータフローで OData 接続を作成したことがない場合、自動的に選択されます。 |
    | つながり名 | 必要に応じて、接続名を変更できますが、値は自動的に入力されます。 |  |
    | オンプレミス データ ゲートウェイ | ありません。 このクラウド サービスへの接続には、オンプレミス データ ゲートウェイは必要ありません。 |
    | 認証の種類 | 組織のアカウント。 **サイン イン** を選択して、接続に関連付けられたアカウントを認証するサイン イン ダイアログを開きます。 |     

    > [!IMPORTANT] 
    > Azure AD 認証を構成するには、ブラウザのポップアップとクッキー ブロッカーを無効にします。 これは、 Common Data Service OData エンドポイントやその他の OAuth ベースの認証データ ソースを使用していることと共通しています。 
    
1. 右下の**次へ**を選択します。

## <a name="step-4-select-and-transform-data-with-power-query"></a>手順 4: Power Query でデータを選択して変換する 

Power Query を使用してテーブルを選択し、要件に合わせてデータを変換します。

まず、転送する必要があるエンティティを選択します。 ソース環境のすべてのエンティティを参照し、各エンティティの一部のデータをプレビューできます。

> [!div class="mx-imgBorder"]
> ![Power Query ナビゲーター](./media/edit-queries-for-selected-entities.png "Power Query ナビゲーター")

1. 必要に応じて 1 つまたは複数のエンティティを選択し、続いて**データの変換**を選択します。

    > [!NOTE]
    > 関連付けをインポートする際は、子エンティティの前に親エンティティのデータフローをインポートする必要があることに注意してください。 子データフローのデータは、正しくマップするためにデータが親エンティティに存在する必要があります。そうでない場合、エラーがスローされる可能性があります。
 
1. **Power Query - クエリの編集**ウィンドウで、インポート前にクエリを変換できます。

    - データを移行するだけの場合は、ここで何も変更する必要はありません。 

    - 不要な列の数を減らすと、より大きなデータ セットのデータフロー パフォーマンスが向上します。

    > [!TIP]
    > 同じ OData コネクタの**データの取得**リボン オプションで戻って、さらにテーブルを選択できます。

1. 右下の**次へ**を選択します。

## <a name="step-5-configure-target-environment-settings"></a>ステップ 5: ターゲット環境設定を構成する

このセクションでは、ターゲット環境設定を定義する方法について説明します。

### <a name="step-51-map-entities"></a>ステップ 5.1: エンティティのマップ 

選択したエンティティごとに、これら設定でエンティティをインポートする動作を選択し、**次へ**を選択します。

> [!div class="mx-imgBorder"]
> ![エンティティのマップ](./media/map-entities-to-target.png "エンティティのマップ")

- **既存のエンティティへの読み込み (推奨)**

    - データフローはソース環境のエンティティからターゲット環境にデータを同期します。同じエンティティ スキーマがターゲット環境ですでに定義されています。

    - 理想としては、ターゲット環境とソース環境の両方で同じソリューションを使用して、データ転送をシームレスにします。 事前定義されたエンティティを使用するもう 1 つの利点は、エンティティが定義済のソリューションと接頭辞をより詳細に制御できることです。
    
    - **クエリの出力で存在しない行を削除する**を選択します。 これにより、関連付けは検索の値を維持するため、正しくマップされます。
    
    - スキーマがソース テーブルとターゲット テーブルの両方で同一である場合は、**自動マッピング**ボタンを選択して、フィールドを迅速にマッピングします。

    - ターゲット環境でのキー構成が必要です (一意の識別子フィールドは変更できません)。

- **新しいエンティティへの読み込み (非推奨)**

    - 理想としては、ソース環境と同じソリューション インポートからターゲット環境で定義されたエンティティが存在している必要があります。 ただし、これが実行できない場合があるため、読み込み先となる既存のエンティティが存在しない場合に選択できるオプションとして扱います。 

    - ターゲット環境の既定のソリューションに新しいカスタム エンティティを作成します。

- **読み込まない**というオプションがありますが、読み込まれていないエンティティをデータフローに含めないでください。 このメニューから**戻る**を選択して Power Query メニューに戻り、不要なエンティティを削除します。

### <a name="step-52-refresh-settings"></a>ステップ 5.2: 更新設定

これは 1 度限りの移行であるため**手動で更新する**を選択し、**作成**を選択してください。 

## <a name="step-6-run-the-dataflow"></a>ステップ 6: データフローを実行する

初回のデータフローの読み込みは、**作成**ボタンを選択したタイミングで開始します。 

> [!div class="mx-imgBorder"]
> ![手動で更新](./media/initiate-dataflow-process.png "手動で更新")

データフロー リストで **(...)** を選択して、データフローを手動で開始できます。 必ず親フローが完了した後に依存データフローを実行してください。

> [!div class="mx-imgBorder"]
> ![手動で更新](./media/refresh-dataflow-manually.png "手動で更新") 

## <a name="tips"></a>ヒント

- 最初に 1 つのエンティティで手順を試し、次にすべてのデータフローを構築します。

- 大量のデータを含むエンティティがさらにある場合は、個々のエンティティに対して複数の個別のデータフローを構成することを検討します。

- 一対多の関連付けでは、エンティティごとに個別のデータフローが必要となります。 子エンティティの前に、親 (別名: 一、または独立) エンティティのデータフローを構成して実行します。

- データフローの更新でエラーが発生した場合は、更新履歴をデータフロー リストの **(...)** メニューで表示し、各更新ログをダウンロードします。

## <a name="limitations"></a>制限

- 多対多の関連付けがされたデータのインポートには対応していません。

- 親データフローは、子データフローの前に実行するように手動で構成する必要があります。
